{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4abb7b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378735a6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ProbParam:\n",
    "    def __init__(self):\n",
    "        self.w = [1, 2, 4, 8, 16]\n",
    "        self.c = [1., 1., 1., 1., 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81c70f4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "prob = ProbParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410e7513",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define the function for which you want to compute the derivative\n",
    "def my_function(x):\n",
    "    lw = len(prob.w)\n",
    "    y = torch.zeros_like(x)\n",
    "    for i in range(lw):\n",
    "        w = prob.w[i]\n",
    "        c = prob.c[i]\n",
    "        y += c * torch.sin(w * np.pi * x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96a921",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Second derivative\n",
    "def my_function_2der(x):\n",
    "    lw = len(prob.w)\n",
    "    y = torch.zeros_like(x)\n",
    "    for i in range(lw):\n",
    "        w = prob.w[i]\n",
    "        c = prob.c[i]\n",
    "        y += c * (w * w * np.pi * np.pi) * torch.sin(w * np.pi * x)\n",
    "    return (-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e6f2f9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Points at which you want to compute the derivative\n",
    "# You can replace this with your own set of points\n",
    "ax = 0.0\n",
    "bx = 1.0\n",
    "ntrain = 30\n",
    "x_train_np = np.linspace(ax, bx, ntrain)[:, None][1:-1]\n",
    "x_train = torch.tensor(x_train_np, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba039e",
   "metadata": {},
   "source": [
    "Compute the derivative of the function at the given points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca2a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = my_function(x_train) #.clone().detach().requires_grad_(True)\n",
    "du_dx_ad = torch.autograd.grad(u, x_train, grad_outputs=torch.ones_like(u), create_graph=True)\n",
    "du_dx_ad = du_dx_ad[0]\n",
    "d2u_dx2_ad = torch.autograd.grad(du_dx_ad, x_train, grad_outputs=torch.ones_like(du_dx_ad), create_graph=True)\n",
    "d2u_dx2_ad = d2u_dx2_ad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1e-5\n",
    "h_v = h * torch.ones_like(x_train)\n",
    "u = my_function(x_train)\n",
    "u_plus = my_function(x_train + h_v)\n",
    "u_minus = my_function(x_train - h_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2u_dx2_fd = (u_plus[:, 0] + u_minus[:, 0] - 2 * u[:, 0]) / (h ** 2)\n",
    "d2u_dx2_fd = (u_plus[:, 0] + u_minus[:, 0] - 2 * u[:, 0]) / (h ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fef4ea",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "d2u_dx2_fd = d2u_dx2_fd.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83943a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2u_dx2 = my_function_2der(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8101f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print(f\"FD-Autograd error: {torch.norm(d2u_dx2_fd - d2u_dx2_ad)/torch.norm(d2u_dx2_ad):.4e} \")\n",
    "print(f\"FD-Exact error: {torch.norm(d2u_dx2_fd - d2u_dx2)/torch.norm(d2u_dx2):.4e} \")\n",
    "print(f\"Autograd-Exact error: {torch.norm(d2u_dx2_ad - d2u_dx2)/torch.norm(d2u_dx2):.4e} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa103603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, gradient in zip(x_train, gradients):\n",
    "#    print(f\"Point: {x.item()}, Derivative: {gradient.item()}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
