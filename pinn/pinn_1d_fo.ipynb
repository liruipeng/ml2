{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197eaeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1D PINN model to solve the problem:\n",
    "            -u_xx + r*u = f\n",
    "and homogeneous boundary conditions (BC).\n",
    "The analytical solution is\n",
    "   1. u(x) = exp(-2x^2) + 1 / 2\n",
    "   2. u(x) = sum_k c_k * sin(w_k * pi * x)\n",
    "and so,\n",
    "   1. f = (4 - 16x^2) exp(-2x^2)\n",
    "   2. f = sum_k c_k * (w_k^2 * pi^2 + r) * sin(w_k * pi * x)\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ea1573",
   "metadata": {},
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b953b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbParam:\n",
    "    def __init__(self):\n",
    "        self.problem = None\n",
    "        self.w = None\n",
    "        self.c = None\n",
    "        self.r = None\n",
    "        #\n",
    "        self.dtype = torch.get_default_dtype()\n",
    "        self.np_dtype = np.float32\n",
    "        if self.dtype == torch.float64:\n",
    "            self.np_dtype = np.float64\n",
    "        elif self.dtype == torch.float32:\n",
    "            self.np_dtype = np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7ae249",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = ProbParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d42065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, dim_inputs, dim_outputs, dim_hidden: list,\n",
    "                 num_lev,\n",
    "                 act_u: nn.Module = nn.ReLU(),\n",
    "                 act_du: nn.Module = nn.ReLU()) -> None:\n",
    "        \"\"\"Simple neural network with linear layers and non-linear activation function\n",
    "        This class is used as universal function approximate for the solution of\n",
    "        partial differential equations using PINNs\n",
    "        Args:\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_lev = num_lev\n",
    "        self.dim_inputs = dim_inputs\n",
    "        self.dim_outputs = dim_outputs\n",
    "\n",
    "        layer_dim = [dim_inputs] + dim_hidden + [dim_outputs]\n",
    "        self.linears_u = nn.ModuleList(\n",
    "            [nn.Linear(layer_dim[i], layer_dim[i+1]) for i in range(len(layer_dim) - 1)],\n",
    "        )\n",
    "\n",
    "        self.linears_du = nn.ModuleList(\n",
    "            [nn.Linear(layer_dim[i], layer_dim[i+1]) for i in range(len(layer_dim) - 1)],\n",
    "        )\n",
    "\n",
    "        self.act_u = act_u\n",
    "        self.act_du = act_du\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        num_layers = len(self.linears_u)\n",
    "        out_u = x\n",
    "        out_du = x\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            if i < num_layers - 1:\n",
    "                out_u = self.act_u(self.linears_u[i](out_u))\n",
    "                out_du = self.act_du(self.linears_du[i](out_du))\n",
    "            else:\n",
    "                out_u = self.linears_u[i](out_u)\n",
    "                out_du = self.linears_du[i](out_du)\n",
    "\n",
    "        out = torch.cat((out_u, out_du), dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def get_solution(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        y = self.forward(x)\n",
    "        # out = torch.zeros((x.shape[0], self.dim_outputs), device=device)\n",
    "        out = y\n",
    "        # for i in range(self.num_lev):\n",
    "        #     out += y[:, i * self.dim_outputs: (i + 1) * self.dim_outputs]\n",
    "        return out\n",
    "\n",
    "    # def _init_weights(self, m):\n",
    "    #    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "    #        nn.init.ones_(m.weight)\n",
    "    #        m.bias.data.fill_(0.01)\n",
    "    #    if type(m) == nn.Linear:\n",
    "    #        torch.nn.init.xavier_uniform(m.weight)  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce35b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mesh:\n",
    "    def __init__(self, ntrain, neval, ax, bx):\n",
    "        self.ntrain = ntrain\n",
    "        self.neval = neval\n",
    "        self.ax = ax\n",
    "        self.bx = bx\n",
    "        # training sample points (excluding the two points on the boundaries)\n",
    "        x_train_np = np.linspace(self.ax, self.bx, self.ntrain)[:, None][1:-1].astype(prob.np_dtype)\n",
    "        x_eval_np = np.linspace(self.ax, self.bx, self.neval)[:, None].astype(prob.np_dtype)\n",
    "        self.x_train = torch.tensor(x_train_np, requires_grad=True).to(device)\n",
    "        self.x_train_bc = torch.tensor([[ax], [bx]], requires_grad=True).to(device)\n",
    "        self.x_eval = torch.tensor(x_eval_np, requires_grad=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad975e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source term\n",
    "def f1(x):\n",
    "    y = (4 - 16 * x ** 2) * torch.exp(-2 * x ** 2)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d00680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    lw = len(prob.w)\n",
    "    r = prob.r\n",
    "    y = torch.zeros_like(x)\n",
    "    for i in range(lw):\n",
    "        w = prob.w[i]\n",
    "        c = prob.c[i]\n",
    "        y += c * (w * w * np.pi * np.pi + r) * torch.sin(w * np.pi * x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9241b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if prob.problem == 1:\n",
    "        return f1(x)\n",
    "    elif prob.problem == 2:\n",
    "        return f2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e4ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_ex1(x):\n",
    "    y = torch.exp(-2 * x ** 2) + 1 / 2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact solution\n",
    "def u_ex2(x):\n",
    "    lw = len(prob.w)\n",
    "    y = torch.zeros_like(x)\n",
    "    for i in range(lw):\n",
    "        w = prob.w[i]\n",
    "        c = prob.c[i]\n",
    "        y += c * torch.sin(w * np.pi * x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf26f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_ex(x):\n",
    "    if prob.problem == 1:\n",
    "        return u_ex1(x)\n",
    "    elif prob.problem == 2:\n",
    "        return u_ex2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49126b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pinn_loss_fo(model, mesh):\n",
    "    x = mesh.x_train\n",
    "    x_bc = mesh.x_train_bc\n",
    "    z = model(x)\n",
    "    z_bc = model(x_bc)\n",
    "    loss_func = nn.MSELoss()\n",
    "\n",
    "    interior2 = None\n",
    "    boundary = None\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(model.num_lev):\n",
    "        u = z[:, 2 * i].unsqueeze(-1)\n",
    "        s = z[:, 2 * i + 1].unsqueeze(-1)\n",
    "        du_dx, = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)\n",
    "        ds_dx, = torch.autograd.grad(s, x, grad_outputs=torch.ones_like(s), create_graph=True)\n",
    "        u_bc = z_bc[:, 2 * i].unsqueeze(-1)\n",
    "        # interior/boundary loss\n",
    "        if i == 0:\n",
    "            interior1 = du_dx + s\n",
    "            interior2 = ds_dx + prob.r * u - f(x)\n",
    "            boundary = u_bc - u_ex(x_bc)\n",
    "        else:\n",
    "            interior1 = du_dx + s\n",
    "            interior2 = interior2.detach().clone() + ds_dx + prob.r * u\n",
    "            boundary = boundary.detach().clone() + u_bc\n",
    "        # total loss\n",
    "        loss_i1 = loss_func(interior1, torch.zeros_like(interior1))\n",
    "        loss_i2 = loss_func(interior2, torch.zeros_like(interior2))\n",
    "        loss_b = loss_func(boundary, torch.zeros_like(boundary))\n",
    "        if i == 0:\n",
    "            loss = loss_i1 + loss_i2 + loss_b\n",
    "        else:\n",
    "            loss = loss + loss_i1 + loss_i2 + loss_b\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecad92ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function for the PINN\n",
    "class Loss:\n",
    "    def __init__(self, model, mesh, t):\n",
    "        self.model = model\n",
    "        self.mesh = mesh\n",
    "        self.type = t\n",
    "\n",
    "    def loss(self):\n",
    "        # x_train_np = np.random.uniform(self.mesh.ax, self.mesh.bx, self.mesh.ntrain)[:, None].astype(prob.np_dtype)\n",
    "        # self.mesh.x_train = torch.tensor(x_train_np, requires_grad=True)\n",
    "\n",
    "        loss = pinn_loss_fo(model=self.model, mesh=self.mesh)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1686c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training loop\n",
    "def train(model, mesh, criterion, iterations, learning_rate, num_check, num_plots):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    check_freq = (iterations + num_check - 1) // num_check\n",
    "    plot_freq = (iterations + num_plots - 1) // num_plots\n",
    "    fig, ax = plt.subplots(num_plots + 1)\n",
    "    fig2, ax2 = plt.subplots(num_plots)\n",
    "\n",
    "    u_analytic = u_ex(mesh.x_eval)\n",
    "    ax[0].plot(mesh.x_eval.cpu().detach().numpy(), u_analytic.cpu().detach().numpy(), linestyle='-',\n",
    "               color=\"black\")\n",
    "    ax[-1].plot(mesh.x_eval.cpu().detach().numpy(), u_analytic.cpu().detach().numpy(), linestyle='-',\n",
    "                color=\"black\", alpha=0.5)\n",
    "    ax_i = 1\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # we need to set to zero the gradients of all model parameters (PyTorch accumulates grad by default)\n",
    "        optimizer.zero_grad()\n",
    "        # compute the loss value for the current batch of data\n",
    "        loss = criterion.loss()\n",
    "        # backpropagation to compute gradients of model param respect to the loss. computes dloss/dx\n",
    "        # for every parameter x which has requires_grad=True.\n",
    "        loss.backward()\n",
    "        # update the model param doing an optim step using the computed gradients and learning rate\n",
    "        optimizer.step()\n",
    "\n",
    "        if np.remainder(i + 1, check_freq) == 0 or i == iterations - 1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                u_eval = model.get_solution(mesh.x_eval)[:, 0].unsqueeze(-1)\n",
    "                error = u_analytic - u_eval\n",
    "                print(f\"Iteration {i:6d}/{iterations:6d}, PINN Loss: {loss.item():.4e}, \"\n",
    "                      f\"Err 2-norm: {torch.norm(error): .4e}, \"\n",
    "                      f\"inf-norm: {torch.max(torch.abs(error)):.4e}\")\n",
    "            model.train()\n",
    "\n",
    "        if np.remainder(i + 1, plot_freq) == 0 or i == iterations - 1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                u_train = model.get_solution(mesh.x_train)[:, 0].unsqueeze(-1)\n",
    "                u_eval = model.get_solution(mesh.x_eval)[:, 0].unsqueeze(-1)\n",
    "                error = u_analytic - u_eval\n",
    "                # plot\n",
    "                ax[ax_i].scatter(mesh.x_train.cpu().detach().numpy(), u_train.cpu().detach().numpy(), color=\"red\",\n",
    "                                 label=\"Sample training points\")\n",
    "                ax[ax_i].plot(mesh.x_eval.cpu().detach().numpy(), u_eval.cpu().detach().numpy(), linestyle='-',\n",
    "                              marker=',', alpha=0.5)\n",
    "                ax2[ax_i - 1].plot(mesh.x_eval.cpu().detach().numpy(), error.cpu().detach().numpy())\n",
    "                ax_i += 1\n",
    "            model.train()\n",
    "\n",
    "    for i in range(len(ax)):\n",
    "        if i < len(ax) - 1:\n",
    "            ax[i].get_xaxis().set_visible(False)\n",
    "        # ax[i].set_yscale('symlog')\n",
    "    for i in range(len(ax2) - 1):\n",
    "        if i < len(ax2) - 1:\n",
    "            ax2[i].get_xaxis().set_visible(False)\n",
    "        # ax2[i].set_yscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c2950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    torch.manual_seed(0)\n",
    "    eval_resolution = 256\n",
    "    # Generate training data\n",
    "    # number of point for training\n",
    "    nx = 128\n",
    "    prob.problem = 2\n",
    "    prob.w = [4]#[1, 2, 4, 8, 16]\n",
    "    prob.c = [1., 1., 1., 1., 1.]\n",
    "    prob.r = 0\n",
    "    num_check = 100\n",
    "    num_plots = 4\n",
    "    iterations = 10000\n",
    "    # Domain is interval [ax, bx] along the x-axis\n",
    "    ax = 0.0\n",
    "    bx = 1.0\n",
    "    #\n",
    "    loss_type = 0\n",
    "    #\n",
    "    mesh = Mesh(ntrain=nx, neval=eval_resolution, ax=ax, bx=bx)\n",
    "    # Create an instance of the PINN model\n",
    "    model = PINN(dim_inputs=1, dim_outputs=1, dim_hidden=[32, 32], num_lev=1, act_u=nn.Tanh(),\n",
    "                 act_du=nn.ReLU())\n",
    "    print(model)\n",
    "    model.to(device)\n",
    "    # Exact solution\n",
    "    # u_analytic = u_ex(mesh.x_eval)\n",
    "    # Train the PINN model\n",
    "    loss = Loss(mesh=mesh, model=model, t=loss_type)\n",
    "    #\n",
    "    train(model=model, mesh=mesh, criterion=loss, iterations=iterations, learning_rate=1e-3,\n",
    "          num_check=num_check, num_plots=num_plots)\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb39316",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    err = main()\n",
    "    plt.show()\n",
    "    sys.exit(err)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
