# -*- coding: utf-8 -*-
"""pinn_pred_corr.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wLEUdDFkmGk7LQX6G5e3RoJtTmTg-hKy
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import math
from functorch import make_functional, grad, vmap # not really needed for now
from scipy.interpolate import interpolate
import matplotlib.pyplot as plt
from torch.functional import norm

torch.manual_seed(0)

class PINN(nn.Module):
    def __init__(
        self,
        num_inputs: int = 1,
        num_outputs: int = 2,
        num_hidden: int = 2,
        dim_hidden: int = 10,
        act: nn.Module = nn.Tanh(),
    ) -> None:
        """Simple neural network with linear layers and non-linear activation function
        This class is used as universal function approximator for the solution of
        partial differential equations using PINNs
        Args:
            num_inputs (int, optional): The number of input dimensions
            num_outputs (int, optional): The number of outputs of the model, in general is 1
            num_hidden (int, optional): The number of hidden layers in the model
            dim_hidden (int, optional): The number of neurons for each hidden layer
            act (nn.Module, optional): The type of non-linear activation function to be used
        """
        super().__init__()

        self.layer_in = nn.Linear(num_inputs, dim_hidden) #, bias=False)
        self.layer_out = nn.Linear(dim_hidden, num_outputs) #, bias=False)

        num_middle = num_hidden - 1
        self.middle_layers = nn.ModuleList(
            [nn.Linear(dim_hidden, dim_hidden) for _ in range(num_middle)]
        )

        self.act = act   # activation function

        self.num_inputs = num_inputs
        self.num_outputs = num_outputs

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        out = self.act(self.layer_in(x))

        for layer in self.middle_layers:
            out = self.act(layer(out)) # self.act()

        out = self.layer_out(out)

        out[:,0] = out[:,0] + out[:,1]

        return out # self.layer_out(out) # torch.sum(self.layer_out(out), dim = 1)

class Mesh:
      def __init__(self,nx,ax,bx):
          self.nx=nx
          self.ax=ax
          self.bx=bx
          self.int_nodes=nx-2
          self.x_train = np.linspace(self.ax, self.bx, self.nx) # nx points and nx-1 sub-intervals
          self.x_train_tensor=torch.from_numpy(self.x_train.flatten()[:,None]).float()

          self.x_train_bc=np.vstack((self.x_train[0],self.x_train[-1])).flatten()[:,None]
          self.x_train_tensor_bc = torch.from_numpy(self.x_train_bc).float()


          # internal nodes
          self.x_train_in = self.x_train[1:nx-1].flatten()[:,None]

          self.x_train_tensor_in = torch.from_numpy(self.x_train_in).float()

# Source term
def f(x,k):
    return k**2*np.pi**2*torch.sin(k*np.pi*x) #

# Define the loss function for the PINN
def PINN_loss(model, mesh):
    # interior data
    x=mesh.x_train_tensor_in
    x.requires_grad_(True)

    u = model(x)
    '''
    print("This is u after model")
    print(u)
    print("Second column of u")
    print(u[:,1])
    '''
    du_dx, = torch.autograd.grad(u[:,0], x, grad_outputs=torch.ones_like(u[:,0]), create_graph=True)
    d2u_dx2, = torch.autograd.grad(du_dx, x, grad_outputs=torch.ones_like(du_dx), create_graph=True)

    # interior loss
    k=8
    interior = d2u_dx2 + f(mesh.x_train_tensor_in,k)

    # boundary data
    x_boundary=mesh.x_train_tensor_bc
    x_boundary.requires_grad_(True)

    u_boundary = model(x_boundary)
    # boundary loss
    boundary = u_boundary[:,0]

    # residual equation
    de_dx, = torch.autograd.grad(u[:,1], x, grad_outputs=torch.ones_like(u[:,1]), create_graph=True)
    d2e_dx2, = torch.autograd.grad(de_dx, x, grad_outputs=torch.ones_like(de_dx), create_graph=True)
    correction = d2e_dx2 + interior

    # boundary residual
    boundary_err = u_boundary[:,1]

    loss = nn.MSELoss()
    loss_value=loss(interior, torch.zeros_like(interior)) + loss(boundary, torch.zeros_like(boundary)) + loss(correction, torch.zeros_like(correction)) + loss(boundary_err, torch.zeros_like(boundary_err))

    return loss_value

# Define the training loop
def train(model, mesh, iterations, learning_rate):
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    for i in range(iterations):

        optimizer.zero_grad() # we need to set to zero the gradients of all model parameters (PyTorch accumulates grad by default)
        loss = PINN_loss(model, mesh) # compute the loss value for the current batch of data
        loss.backward() # backpropagation to compute gradients of model param respect to the loss. computes dloss/dx for every parameter x which has requires_grad=True.
        optimizer.step() # update the model param doing an optim step using the computed gradients and learning rate.

        if (i+1) % 2000 == 0:
            print(f"Iteration {i+1}/{iterations}, Loss: {loss.item()}")

def u_ex(x):
    k=8
    return torch.sin(k*np.pi*x) # torch.zeros_like(x) # 1/np.pi**2 * torch.sin(np.pi*x) #
def plot_solution(ax, mesh, u_star):
    X_star = mesh.x_train
    a = X_star.min(0)
    b = X_star.max(0)

    ax.semilogy(X_star,u_star.flatten())
    ax.semilogy(X_star,u_ex(mesh.x_train_tensor).flatten())



# Generate training data
# PREDICTION AND CORRECTION
nx=40 # number of point in x axis

# Domain is Omega=[ax,bx]x[ay,by]
# Interval [a,b] along the x axis
ax=0
bx=1

mesh=Mesh(nx,ax,bx)

# Create an instance of the PINN model
model = PINN()
print(model)

# Train the PINN model
u_exact=u_ex(mesh.x_train_tensor)
# fig, ax = plt.subplots(1) # plt.figure(1) #


model.train() # this tells pytorch to update the weigths
train(model, mesh, iterations=150000, learning_rate=1e-3)

model.eval()
prediction = model.forward(mesh.x_train_tensor)
# Transoform the prediction into a numpy object for the plot
prediction_np= prediction.detach().numpy()#[:,0]

# Prediction and exact solution
plt.figure(2)
plt.xlabel('x')
plt.ylabel('u(x)')
plt.plot(mesh.x_train,u_ex(mesh.x_train_tensor), linestyle = '-',label='Exact')
plt.plot(mesh.x_train,prediction_np, marker = '+', label=['PINN','Error'])
plt.legend(loc='best')
plt.show()
